{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f9ce3-8726-4a08-abd0-172643a93d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "from multiprocessing import  Pool\n",
    "import ast\n",
    "import os \n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4f872-fa0d-4a31-867e-6018a030e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ywang216/.config/gcloud/application_default_credentials.json'\n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-boussard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f8241-0a6b-43bd-86f5-5fa374b92210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3900f49-dc7b-455d-8a00-a449dd82d4e2",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ae168-3e1d-4b7f-9259-c5f9eb34fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT pat_deid, result_time, lab_name, ord_num_value FROM `som-nero-phi-boussard.stanfordmed_datalake.shc_lab_result`\n",
    "WHERE lab_name IN\n",
    "(SELECT lab_name\n",
    "FROM `som-nero-phi-boussard.stanfordmed_datalake.shc_lab_result`\n",
    "GROUP BY lab_name\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 20) AND pat_deid IN (SELECT pat_deid FROM `som-nero-phi-boussard.ID_delirium_elderly.shc_note_20230119`);\n",
    "    \"\"\"\n",
    "df_lab = pd.read_gbq(QUERY, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078926c-93c6-45c9-94ff-80d214aec65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab.to_csv(\"patient_lab_measurements.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eace6d9-5c3c-4203-a540-ce7772f5b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY= \"\"\"\n",
    "SELECT pat_deid, recorded_time, row_disp_name, meas_value FROM `som-nero-phi-boussard.stanfordmed_datalake.shc_flowsheet`\n",
    "WHERE grp_disp_name = 'Vitals'\n",
    "AND pat_deid IN (SELECT pat_deid FROM `som-nero-phi-boussard.ID_delirium_elderly.shc_note_20230119`);\n",
    "    \"\"\"\n",
    "df_vital = pd.read_gbq(QUERY, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973e1f3-e88e-4c0a-ac22-933b1f392c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vital.to_csv(\"patient_vitals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e366cbd-b455-408c-99a7-7a04d09df16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY= \"\"\"\n",
    "SELECT pat_deid, birth_date, sex, ethnic_group, race FROM `som-nero-phi-boussard.stanfordmed_datalake.shc_patient` \n",
    "where pat_deid IN (SELECT pat_deid FROM `som-nero-phi-boussard.ID_delirium_elderly.shc_note_20230119`);\n",
    "    \"\"\"\n",
    "df_demographics = pd.read_gbq(QUERY, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67513053-69b9-4b15-ba9c-3ca9403ccfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.to_csv(\"patient_demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9167f0-5831-4f0b-aeb3-fa7cc1b4eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30-day readmission\n",
    "QUERY= \"\"\"\n",
    "WITH RankedAdmissions AS (\n",
    "    SELECT \n",
    "        pat_deid, \n",
    "        hosp_admsn_time, \n",
    "        hosp_disch_time,\n",
    "        LAG(hosp_disch_time) OVER (PARTITION BY pat_deid ORDER BY hosp_admsn_time) AS previous_discharge_time,\n",
    "        ROW_NUMBER() OVER (PARTITION BY pat_deid ORDER BY hosp_admsn_time) AS admission_rank\n",
    "    FROM \n",
    "        `som-nero-phi-boussard.stride_datalake.shc_hospitalization` \n",
    "),\n",
    "ReadmissionAnalysis AS (\n",
    "    SELECT \n",
    "        pat_deid,\n",
    "        hosp_admsn_time,\n",
    "        previous_discharge_time,\n",
    "        CASE \n",
    "            WHEN admission_rank = 1 THEN 0 -- First admission, so cannot be a readmission\n",
    "            WHEN DATE_DIFF(hosp_admsn_time, previous_discharge_time, DAY) <= 30 THEN 1\n",
    "            ELSE 0\n",
    "        END AS readmission_30_days\n",
    "    FROM \n",
    "        RankedAdmissions\n",
    ")\n",
    "SELECT \n",
    "    pat_deid,\n",
    "    MAX(readmission_30_days) AS readmission_30_days -- To handle patients with multiple readmissions\n",
    "FROM \n",
    "    ReadmissionAnalysis \n",
    "WHERE pat_deid in (SELECT pat_deid FROM `som-nero-phi-boussard.ID_delirium_elderly.shc_note_20230119`)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df206ee-7d91-4fba-880c-1317fac063ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY= \"\"\"\n",
    "SELECT pat AS pat_deid, surg_date, note_date, surg_family, surg_description, note_desc, note FROM `som-nero-phi-boussard.ID_delirium_elderly.test` \n",
    "WHERE pat in (SELECT pat_deid FROM `som-nero-phi-boussard.ID_delirium_elderly.shc_note_20230119`) \n",
    "AND ip_note_type IN ('H&P', 'ER NOTES', 'ED Notes', 'Nursing Note', 'Progress Notes');\n",
    "    \"\"\"\n",
    "df_notes = pd.read_gbq(QUERY, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dad389-45fe-45af-a09f-1c2870ba1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT distinct pat_deid\n",
    "  FROM `som-nero-phi-boussard.ID_delirium_elderly.flowsheet`  where (row_disp_name='CAM - ICU Result' or row_disp_name='Is CAM Positive?') and meas_value in ('Positive', 'Yes','1');\n",
    "  \"\"\"\n",
    "df_CAM_pos = pd.read_gbq(QUERY, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d95f6c-b71a-44ee-85c6-f0820320184d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5d3200e-c2d8-403a-8519-76f7100ffe8b",
   "metadata": {},
   "source": [
    "# Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759f970-5357-4c4b-ad0e-7bc8d37cc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "def calculate_fairness_metrics(labels, predictions, demographics, sensitive_class):\n",
    "    \"\"\"\n",
    "    Calculate fairness metrics such as Equal Opportunity and Equal Odds.\n",
    "\n",
    "    Args:\n",
    "    labels (array): True labels.\n",
    "    predictions (array): Model predictions.\n",
    "    demographics (array): Demographic information (sensitive attribute).\n",
    "    sensitive_class (int): The value in demographics to be treated as the sensitive class.\n",
    "\n",
    "    Returns:\n",
    "    dict: Fairness metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Indices for the sensitive class\n",
    "    sensitive_indices = demographics == sensitive_class\n",
    "    non_sensitive_indices = ~sensitive_indices\n",
    "\n",
    "    # Confusion matrix for sensitive class\n",
    "    tn_s, fp_s, fn_s, tp_s = confusion_matrix(labels[sensitive_indices], predictions[sensitive_indices]).ravel()\n",
    "    # Confusion matrix for non-sensitive class\n",
    "    tn_ns, fp_ns, fn_ns, tp_ns = confusion_matrix(labels[non_sensitive_indices], predictions[non_sensitive_indices]).ravel()\n",
    "\n",
    "    # Metrics for sensitive class\n",
    "    tpr_s = tp_s / (tp_s + fn_s) if (tp_s + fn_s) != 0 else 0\n",
    "    fpr_s = fp_s / (fp_s + tn_s) if (fp_s + tn_s) != 0 else 0\n",
    "\n",
    "    # Metrics for non-sensitive class\n",
    "    tpr_ns = tp_ns / (tp_ns + fn_ns) if (tp_ns + fn_ns) != 0 else 0\n",
    "    fpr_ns = fp_ns / (fp_ns + tn_ns) if (fp_ns + tn_ns) != 0 else 0\n",
    "\n",
    "    # Equal Opportunity Difference\n",
    "    eod = tpr_s - tpr_ns\n",
    "\n",
    "    # Equalized Odds Difference\n",
    "    eod_fpr = fpr_s - fpr_ns\n",
    "    eod_tpr = tpr_s - tpr_ns\n",
    "    avg_eod = (abs(eod_fpr) + abs(eod_tpr)) / 2\n",
    "\n",
    "    return {\n",
    "        \"TPR Sensitive\": tpr_s,\n",
    "        \"TPR Non-Sensitive\": tpr_ns,\n",
    "        \"FPR Sensitive\": fpr_s,\n",
    "        \"FPR Non-Sensitive\": fpr_ns,\n",
    "        \"Equal Opportunity Difference\": eod,\n",
    "        \"Equalized Odds Difference (FPR)\": eod_fpr,\n",
    "        \"Equalized Odds Difference (TPR)\": eod_tpr,\n",
    "        \"Average Equalized Odds Difference\": avg_eod\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57798705-dfda-4a65-bab9-ecdfd941665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiclass_fairness_metrics(labels, predictions, demographics):\n",
    "    unique_classes = np.unique(demographics)\n",
    "    metrics = {}\n",
    "\n",
    "    for sensitive_class in unique_classes:\n",
    "        sensitive_indices = demographics == sensitive_class\n",
    "        non_sensitive_indices = ~sensitive_indices\n",
    "\n",
    "        tn_s, fp_s, fn_s, tp_s = confusion_matrix(labels[sensitive_indices], predictions[sensitive_indices]).ravel()\n",
    "        tn_ns, fp_ns, fn_ns, tp_ns = confusion_matrix(labels[non_sensitive_indices], predictions[non_sensitive_indices]).ravel()\n",
    "\n",
    "        tpr_s = tp_s / (tp_s + fn_s) if (tp_s + fn_s) != 0 else 0\n",
    "        fpr_s = fp_s / (fp_s + tn_s) if (fp_s + tn_s) != 0 else 0\n",
    "\n",
    "        eod = tpr_s - (tp_ns / (tp_ns + fn_ns))\n",
    "        avg_eod = (abs(fp_s / (fp_s + tn_s) - (fp_ns / (fp_ns + tn_ns))) + abs(eod)) / 2\n",
    "\n",
    "        metrics[sensitive_class] = {\n",
    "            \"TPR\": tpr_s,\n",
    "            \"FPR\": fpr_s,\n",
    "            \"Equal Opportunity Difference\": eod,\n",
    "            \"Average Equalized Odds Difference\": avg_eod\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Synthetic example data\n",
    "np.random.seed(0) # For reproducibility\n",
    "labels = a   # True labels (binary)\n",
    "predictions = c  # Model predictions (binary)\n",
    "demographics = df_demo_test['ethnic_group'].astype(int).to_numpy()  # Sensitive attribute with 5 groups (0, 1, 2, 3, 4)\n",
    "\n",
    "# Calculate fairness metrics\n",
    "fairness_metrics = calculate_multiclass_fairness_metrics(labels, predictions, demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7f7b3-55a5-401a-909f-f4156a862042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictive_parity(y_true, y_pred, sensitive_attrs):\n",
    "    \"\"\"\n",
    "    Calculate the predictive parity (precision equality) for each group defined by a sensitive attribute.\n",
    "    \n",
    "    Args:\n",
    "    y_true (array): True binary labels.\n",
    "    y_pred (array): Predicted binary labels.\n",
    "    sensitive_attrs (array): Array indicating the group each instance belongs to.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary mapping each group to its precision score.\n",
    "    \"\"\"\n",
    "    unique_groups = np.unique(sensitive_attrs)\n",
    "    precision_scores = {}\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_indices = sensitive_attrs == group\n",
    "        precision = precision_score(y_true[group_indices], y_pred[group_indices], zero_division=0, average='weighted')\n",
    "        precision_scores[group] = precision\n",
    "\n",
    "    return precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b49ca4-9090-4314-b6eb-3d8b7831abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tpr_and_fpr(y_true, y_pred, group_mask):\n",
    "    \"\"\"\n",
    "    Calculate True Positive Rate (TPR) and False Positive Rate (FPR) for a given group.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true[group_mask], y_pred[group_mask], labels=[1, 0])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    return tpr, fpr\n",
    "\n",
    "def calculate_sd_for_rates(y_true, y_pred, sensitive_attr):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of TPR and FPR across all classes of a sensitive attribute.\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(sensitive_attr)\n",
    "    tpr_values = []\n",
    "    fpr_values = []\n",
    "\n",
    "    for group in unique_classes:\n",
    "        group_mask = sensitive_attr == group\n",
    "        tpr, fpr = calculate_tpr_and_fpr(y_true, y_pred, group_mask)\n",
    "        tpr_values.append(tpr)\n",
    "        fpr_values.append(fpr)\n",
    "\n",
    "    sd_tpr = np.std(tpr_values, ddof=1)  # Use ddof=1 for sample standard deviation\n",
    "    sd_fpr = np.std(fpr_values, ddof=1)\n",
    "    \n",
    "    return sd_tpr, sd_fpr\n",
    "\n",
    "def calculate_equalized_odds_difference(y_true, y_pred, sensitive_attr):\n",
    "    unique_classes = np.unique(sensitive_attr)\n",
    "    tpr_diffs = []\n",
    "    fpr_diffs = []\n",
    "\n",
    "    for i, group1 in enumerate(unique_classes):\n",
    "        for group2 in unique_classes[i+1:]:\n",
    "            group1_mask = sensitive_attr == group1\n",
    "            group2_mask = sensitive_attr == group2\n",
    "            tpr1, fpr1 = calculate_tpr_and_fpr(y_true, y_pred, group1_mask)\n",
    "            tpr2, fpr2 = calculate_tpr_and_fpr(y_true, y_pred, group2_mask)\n",
    "\n",
    "            tpr_diffs.append(abs(tpr1 - tpr2))\n",
    "            fpr_diffs.append(abs(fpr1 - fpr2))\n",
    "\n",
    "    avg_tpr_diff = np.mean(tpr_diffs)\n",
    "    avg_fpr_diff = np.mean(fpr_diffs)\n",
    "\n",
    "    return avg_tpr_diff, avg_fpr_diff\n",
    "\n",
    "# Calculate Equalized Odds differences\n",
    "avg_tpr_diff, avg_fpr_diff = calculate_equalized_odds_difference(a, b, sensitive_attr_age)\n",
    "\n",
    "print(f\"Average TPR Difference: {avg_tpr_diff:.3f}\")\n",
    "print(f\"Average FPR Difference: {avg_fpr_diff:.3f}\")\n",
    "\n",
    "# Optionally combine into a single metric\n",
    "combined_metric = (avg_tpr_diff + avg_fpr_diff) / 2\n",
    "print(f\"Combined Equalized Odds Metric: {combined_metric:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6ccf5-c99b-44e3-b63e-cc2dd4c464f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDDI\n",
    "y_true = a\n",
    "y_pred = b\n",
    "overall_error_rate = np.mean(y_true != y_pred)\n",
    "\n",
    "# For a sensitive attribute (e.g., gender), create a group mask for each group\n",
    "unique_groups = np.unique(sensitive_attr) \n",
    "\n",
    "group_masks = {group: (sensitive_attr == group) for group in unique_groups}\n",
    "\n",
    "def calculate_normalized_disparity(y_true, y_pred, group_mask, overall_error_rate):\n",
    "    group_error_rate = np.mean(y_true[group_mask] != y_pred[group_mask])\n",
    "    # Normalizing the disparity to be within [0, 1]\n",
    "    normalized_disparity = abs(group_error_rate - overall_error_rate) / max(overall_error_rate, 1 - overall_error_rate)\n",
    "    return normalized_disparity\n",
    "\n",
    "def calculate_eddi(y_true, y_pred, sensitive_attr):\n",
    "    overall_error_rate = np.mean(y_true != y_pred)\n",
    "    unique_groups = np.unique(sensitive_attr)\n",
    "    \n",
    "    normalized_disparities = []\n",
    "    for group in unique_groups:\n",
    "        group_mask = sensitive_attr == group\n",
    "        disparity = calculate_normalized_disparity(y_true, y_pred, group_mask, overall_error_rate)\n",
    "        normalized_disparities.append(disparity)\n",
    "    \n",
    "    eddi = np.mean(normalized_disparities)\n",
    "    return eddi\n",
    "\n",
    "# Example usage\n",
    "eddi_score = calculate_eddi(y_true, y_pred, sensitive_attr)\n",
    "print(f\"EDDI Score: {eddi_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
